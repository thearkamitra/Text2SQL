# Text2SQL Project

This repository contains the codebase for the Text2SQL project.

## Setup Instructions

### 1. Clone the Repository

```bash
git clone <repository-url>
cd Text2SQL
```

### 2. Create a Virtual Environment
The python version used in this project is 3.10.12. Ensure you have it installed on your system.

For this project, it is recommended to use a virtual environment to manage dependencies. You can create one using the following commands:

```bash
python3 -m venv .venv
source .venv/bin/activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```


### 4. Configure Environment Variables

There are some environment variables that need to be set for the project to run correctly. You can copy the example environment file and edit it:

Edit `.env` and fill in the required values:

```
# Example .env file
DATABASE_URL=your_database_url
SECRET_KEY=your_secret_key
```

Refer to the project documentation for details on each variable.

### 5. Download Datasets
There are some requirements for the datasets that are present in this directory. There is a dependency on the `sciencebenchmark_dataset` repository since it contains many of the metadata for the files used.
When in the root directory of the project, run the following command to download the datasets:

```bash
git clone https://github.com/ckosten/sciencebenchmark_dataset.git
```
Once the repository is downloaded and all the previous steps are completed (assuming the virtual environment is activated), the directory structure should look like this:

```Text2SQL/
├── sciencebenchmark_dataset/
├── .venv/
├── requirements.txt
├── .env
├── README.md
└── ...
```
This directory structure is important for the application to function correctly.

## Running the Application

From the root directory of the project, set the `PYTHONPATH` to include the current directory:
```bash
export PYTHONPATH=.
```
### Getting Additional Data

There are some files that are generated by the application which are specific to the `Cordis` dataset. To generate these files, you need to run the following command:

```bash
python utils/generate_cordis_data.py
```
Look into the file incase you want to change any of the parameters.

### Generating description of the columns

There is a file called `column_description.json` in the `datasets` directory that contains the description of the columns in the database. This file should be obtained by adding the ground truth description
of the columns in the database. Since this file is not provided in the repository, you need to generate it manually.

### Generating the SQL queries for the datasets
In this respository, the SQL queries can be generated either by running the following command:

```bash
python  agents/agent.py
```
The file has different argparse arguments that can be used to control the generation of the SQL queries. You can run the command with `--help` to see the available options.

### Evaluating the SQL Queries

The previous scripts will generate the SQL queries for a given human input. Once the SQL queries are generated, you can evaluate them using the following command:

```bash
python eval/evaluate_model_outputs.py --path <path_to_sql_queries>
```
If you pass in a directory, it will evaluate all the SQL queries in that directory. If you pass in a file, it will evaluate only that file.


### Evaluating the Model Outputs

The model outputs are stored in csv format for each model/ configuration. If you want to compare the outputs of different models, there is a jupyter notebook in the `datasets` directory that can be used for analysis. Follow the instructions in the project documentation to start the application.
When opening the notebook, make sure to set the `PYTHONPATH` to include the current directory or set the system path to include the current directory. 





## Additional Information
The model uses the OpenAI and Groq APIs to generate SQL queries. You need to have an API key for both services to run the application.
You can additionally use Ollama to run the models locally.
Please refer to the documentation of the respective services for more information on how to obtain the API keys.

The models that have been used for groq can be found here:
https://console.groq.com/docs/rate-limits
The models that have been used for OpenAI can be found here:
https://platform.openai.com/
The models that are run for Ollama can be found here:
https://ollama.com/models

### Ollama Models
For running the models locally, it is important that the models are downloaded and available in the Ollama repository. You can run the following commands to download the models:

```bash
ollama pull <name_of_model>
```
Ollama should be able to download and run the models locally. Please follow the instructions in the Ollama documentation for more information on how to use the models.


## How to Contribute
If you want to contribute to the project, please feel free to open a pull request or send an issue. If you want to have some questions answered, you can email me at thearkamitra at gmail dot com. 

In the best case scenario, feel free to put in your openai or groq keys and send a pull request. I will be happy to merge it and give you credit for the contribution.

### Some Next Steps
- Currently the project assumes that the datasets that will be used is only the `Cordis` dataset. In the future, we will add support for other datasets as well.
- The project currently uses the OpenAI and Groq APIs to generate SQL queries. In the future, we will add support for other models as well.
- The project currently requires the information about the columns in the database to be provided manually. In the future, we will add support for automatically generating the column descriptions.
- The project currently does not check whether the SQL queries generated are valid or not. In the future, we will add support for validating the SQL queries directly and providing the feedback to the LLMs so that they can loop back and generate better queries.